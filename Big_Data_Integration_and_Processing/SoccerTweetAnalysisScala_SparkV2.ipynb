{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 2.1.0\n",
      "Spark App Name: Apache Toree"
     ]
    }
   ],
   "source": [
    "print(s\"Spark Version: ${spark.version}\\nSpark App Name: ${spark.sparkContext.appName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       country|\n",
      "+--------------+\n",
      "|   afghanistan|\n",
      "|       albania|\n",
      "|       algeria|\n",
      "|american samoa|\n",
      "|       andorra|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sparkDummy = spark\n",
    "import sparkDummy.implicits._\n",
    "import org.apache.spark.sql.functions.{avg, col, upper}\n",
    "\n",
    "val countriesFileDF = spark.read.\n",
    "    format(\"csv\").\n",
    "    load(\"file:///home/ubuntu/UCSD/big-data-3/final-project/country-list.csv\").\n",
    "        as[(String, String)].\n",
    "        select('_c0 as 'country)\n",
    "\n",
    "val countriesDF = countriesFileDF.select(countriesFileDF.columns.map(c => lower(col(c)).alias(c)): _*)\n",
    "countriesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|  some|  123|\n",
      "| still|  104|\n",
      "|   ...|   68|\n",
      "| those|   31|\n",
      "|doubts|    1|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val tweetsDF = spark.read.\n",
    "    format(\"csv\").\n",
    "    load(\"file:///home/ubuntu/UCSD/big-data-3/final-project/tweets.csv\").toDF(\"tweets\")\n",
    "val wordCountDF = tweetsDF.explode(\"tweets\",\"word\")((line: String) => line.trim().replaceAll(\"\"\"[\\p{Punct}&&[^.]]\"\"\", \"\").toLowerCase().split(\" \")).groupBy(\"word\").count()\n",
    "wordCountDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  country|count|\n",
      "+---------+-----+\n",
      "|  albania|    1|\n",
      "|argentina|    3|\n",
      "|australia|    2|\n",
      "|  austria|    5|\n",
      "|  bahamas|    1|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.SparkContext._\n",
    "val joinedDF = countriesDF.join(wordCountDF, \n",
    "                                   countriesDF.col(\"country\") === wordCountDF.col(\"word\")).select('country, 'count)\n",
    "joinedDF.createOrReplaceTempView(\"joined\")\n",
    "joinedDF.cache()\n",
    "joinedDF.count()\n",
    "joinedDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+-------+\n",
      "|tot_cnt|\n",
      "+-------+\n",
      "|     54|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sqlDF1 = spark.sql(\"SELECT count(distinct country) AS tot_cnt FROM joined\")\n",
    "sqlDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedDF.select(\"country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| country|count|\n",
      "+--------+-----+\n",
      "|  france|   79|\n",
      "| nigeria|   67|\n",
      "|  norway|   53|\n",
      "| england|   37|\n",
      "|slovakia|   30|\n",
      "+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sqlDF2 = spark.sql(\"SELECT country, count FROM joined order by count desc\")\n",
    "sqlDF2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| country|count|\n",
      "+--------+-----+\n",
      "|  france|   79|\n",
      "| nigeria|   67|\n",
      "|  norway|   53|\n",
      "| england|   37|\n",
      "|slovakia|   30|\n",
      "+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.select($\"country\", $\"count\").\n",
    "    sort($\"count\".desc).\n",
    "    show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|    country|count|\n",
      "+-----------+-----+\n",
      "|      wales|   24|\n",
      "|netherlands|   13|\n",
      "|      japan|    8|\n",
      "|      kenya|    3|\n",
      "|    iceland|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sqlDF3 = spark.sql(s\"SELECT country, count FROM joined where country in (\\'kenya\\', \\'wales\\', \\'netherlands\\', \\'iceland\\', \\'japan\\') order by count desc\")\n",
    "sqlDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|           count1|\n",
      "+-----------------+\n",
      "|9.666666666666666|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val sqlDF4 = spark.sql(s\"SELECT avg(count) as count1 FROM joined order by count1 desc\")\n",
    "sqlDF4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          avg_cnt|\n",
      "+-----------------+\n",
      "|9.666666666666666|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.agg(avg('count).alias(\"avg_cnt\")).\n",
    "    sort($\"avg_cnt\".desc).\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
